<div align="center">
<img style="vertical-align:middle" height="300" src="logo.svg" />
</div>

This repository is part of the [Holmes ðŸ”Ž benchmark](https://holmes-benchmark.github.io).
It provides code to evaluate an language model on Holmes ðŸ”Ž, the comprehensive option, or FlashHolmes âš¡, the efficient variant.


# ðŸ”Ž How does it work?
To evaluate your desired language model on Holmes ðŸ”Ž or FlashHolmes âš¡, follow these three steps: 
1. **Encoding** Encode inputs of the probing datasets with the language model - more detail [bellow](#encoding).
2. **Probing** Run to probes on the encoded datasets, see [probing](#probing). 
3. **Evaluating** Gather probing results to get an overview of the linguistic knowledge of your chosen language model, following [evaluating](#evaluating).


# ðŸ”Ž <a name="encoding"></a>First <u>Encoding</u>
# ðŸ”Ž <a name="probing"></a>Second <u>Probing</u>
# ðŸ”Ž <a name="evaluating"></a>Third <u>Evaluating</u>


For more details, check out our webpage https://holmes-benchmark.github.io or publication _HOLMES: Benchmark Linguistic Knowledge in Language Models_
